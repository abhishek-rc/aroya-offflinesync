# ============================================
# STRAPI BASIC CONFIGURATION
# ============================================
HOST=0.0.0.0
PORT=1337

# Secrets (generate new ones for production!)
APP_KEYS="toBeModified1,toBeModified2,toBeModified3,toBeModified4"
API_TOKEN_SALT=tobemodified
ADMIN_JWT_SECRET=tobemodified
TRANSFER_TOKEN_SALT=tobemodified
JWT_SECRET=tobemodified
ENCRYPTION_KEY=tobemodified

# ============================================
# DATABASE CONFIGURATION
# ============================================
# PostgreSQL (recommended for Master and production Replica)
DATABASE_CLIENT=postgres
DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_NAME=strapi_db
DATABASE_USERNAME=postgres
DATABASE_PASSWORD=your_password
DATABASE_SSL=false

# SQLite (optional for Replica - works offline)
# DATABASE_CLIENT=sqlite
# DATABASE_FILENAME=.tmp/data.db

# ============================================
# OFFLINE SYNC PLUGIN CONFIGURATION
# ============================================

# Sync Mode: 'master' or 'replica'
# MASTER: Central server that receives updates from ships
# REPLICA: Remote instance (ship) that syncs with master
SYNC_MODE=master

# Ship ID (REQUIRED for replica mode, unique per ship)
# SYNC_SHIP_ID=ship-001

# ============================================
# KAFKA CONFIGURATION
# ============================================

# MASTER: Use localhost (Kafka runs on same machine)
# KAFKA_BROKERS=localhost:9092

# REPLICA: Use ngrok address (from master's ngrok tunnel)
# KAFKA_BROKERS=0.tcp.in.ngrok.io:13988

# Kafka SSL/TLS (set to true for production)
KAFKA_SSL_ENABLED=false

# Kafka SASL Authentication (optional, for production)
# KAFKA_SASL_MECHANISM=plain
# KAFKA_SASL_USERNAME=your_username
# KAFKA_SASL_PASSWORD=your_password

# Kafka Topics
KAFKA_TOPIC_SHIP_UPDATES=ship-updates
KAFKA_TOPIC_MASTER_UPDATES=master-updates

# Kafka Consumer Group Suffix (for development - avoids zombie consumers)
# KAFKA_CONSUMER_GROUP_SUFFIX=dev-12345

# ============================================
# SYNC SETTINGS
# ============================================
SYNC_BATCH_SIZE=100
SYNC_RETRY_ATTEMPTS=3
SYNC_RETRY_DELAY=5000
SYNC_CONNECTIVITY_CHECK_INTERVAL=30000
SYNC_DEBOUNCE_MS=1000

# Content types to sync (empty = sync all)
# SYNC_CONTENT_TYPES=api::article.article,api::product.product

# ============================================
# MEDIA STORAGE CONFIGURATION
# ============================================

# ============================================
# OSS (Alibaba Cloud) - Used by MASTER
# ============================================
OSS_ENABLED=true
OSS_ACCESS_KEY_ID=your_oss_access_key_id
OSS_ACCESS_KEY_SECRET=your_oss_access_key_secret
OSS_REGION=oss-me-central-1
OSS_BUCKET=your-bucket-name
OSS_UPLOAD_PATH=uploads
OSS_BASE_URL=https://your-bucket-name.oss-me-central-1.aliyuncs.com
OSS_TIMEOUT=60000

# ============================================
# MinIO (Local S3-compatible) - Used by REPLICA
# ============================================
# MinIO runs locally on ship for offline access
# Start with: docker-compose -f src/plugins/offline-sync/docker/docker-compose.minio.yml up -d
MINIO_ENDPOINT=http://localhost:9000
MINIO_PORT=9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin123
MINIO_BUCKET=media
MINIO_BASE_URL=http://localhost:9000/media

# ============================================
# MEDIA SYNC OPTIMIZATION (for large buckets)
# ============================================
# For buckets with 10,000+ files, use these settings:
# MEDIA_SYNC_ON_STARTUP=false          # Disable full sync on startup (use on-demand only)
# MEDIA_SYNC_INTERVAL=0                # Disable periodic full sync (0 = disabled)
# MEDIA_DISABLE_FULL_SYNC=true         # Only sync files when content is received (recommended for 10k+ files)
# MEDIA_MAX_FILES_PER_SYNC=1000        # Limit files per sync run (0 = unlimited)

# Default (for small buckets):
# MEDIA_SYNC_ON_STARTUP=true           # Sync all files on startup
# MEDIA_SYNC_INTERVAL=300000           # Sync every 5 minutes
# MEDIA_DISABLE_FULL_SYNC=false        # Allow full sync
# MEDIA_MAX_FILES_PER_SYNC=0           # No limit

# ============================================
# IMAGE & VIDEO PROCESSING
# ============================================
ENABLE_IMAGE_OPTIMIZATION=true
ENABLE_RESPONSIVE_IMAGES=true
ENABLE_VIDEO_COMPRESSION=true
VIDEO_CRF=28
VIDEO_MAX_WIDTH=1920
VIDEO_AUDIO_BITRATE=128k

# ============================================
# CACHE CONFIGURATION
# ============================================
CACHE_ENABLED=true
CACHE_TTL=3600
CACHE_MAX_KEYS=1000
CACHE_CHECK_PERIOD=60
CACHE_RESPECT_NO_CACHE=false
CACHE_DEBUG=false

# ============================================
# DOCKER COMPOSE (for Kafka) - MASTER ONLY
# ============================================
# This is used by docker-compose.yml to configure Kafka's advertised listener
# Update this when ngrok address changes
# KAFKA_EXTERNAL_HOST=0.tcp.in.ngrok.io:13988
